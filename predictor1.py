# app.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import time
import io
import base64
from scipy import stats
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.feature_selection import VarianceThreshold
from statsmodels.stats.outliers_influence import variance_inflation_factor
from scipy.stats import kstest
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
import skfuzzy as fuzz
from skfuzzy import control as ctrl
import warnings
warnings.filterwarnings('ignore')

# Configuraci贸n de la p谩gina
st.set_page_config(
    page_title="Estimador de Precios de Viviendas",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Internacionalizaci贸n (i18n)
language_dict = {
    "ES": {
        "title": "Estimador de Precios de Viviendas",
        "welcome": "Bienvenido al estimador de precios de viviendas",
        "upload_data": "Cargar datos",
        "file_types": "Tipos de archivo admitidos: CSV, XLSX",
        "select_file": "Seleccione un archivo",
        "eda": "An谩lisis Exploratorio (EDA)",
        "correlations": "An谩lisis de Correlaciones",
        "preprocessing": "Limpieza y Preprocesamiento",
        "scaling": "Escalado y Divisi贸n",
        "modeling": "Modelado",
        "validation": "Entrenamiento y Validaci贸n",
        "timeseries": "Pron贸sticos con Series Temporales",
        "report": "Generar Reporte PDF",
        "records": "registros",
        "variables": "variables",
        "numerical": "Num茅ricas",
        "categorical": "Categ贸ricas",
        "missing_data": "Datos faltantes",
        "duplicates": "Datos duplicados",
        "descriptive_stats": "Estad铆sticas Descriptivas",
        "normality_test": "Prueba de Normalidad",
        "visualization": "Visualizaci贸n",
        "correlation_matrix": "Matriz de Correlaci贸n",
        "correlation_heatmap": "Mapa de Calor de Correlaciones",
        "strongest_correlations": "Correlaciones m谩s Fuertes con el Precio",
        "multicolinearity": "An谩lisis de Multicolinealidad",
        "vif": "Factor de Inflaci贸n de Varianza (VIF)",
        "preprocessing_options": "Opciones de Preprocesamiento",
        "imputation": "Imputaci贸n de Valores Faltantes",
        "outlier_treatment": "Tratamiento de Outliers",
        "encoding": "Codificaci贸n de Variables Categ贸ricas",
        "scaling_options": "Opciones de Escalado",
        "train_val_test_split": "Divisi贸n Entrenamiento/Validaci贸n/Prueba",
        "cross_validation": "Validaci贸n Cruzada",
        "model_training": "Entrenamiento de Modelos",
        "model_performance": "Rendimiento de Modelos",
        "timeseries_forecasting": "Pron贸stico de Series Temporales",
        "download_report": "Descargar Reporte PDF",
        "linear_regression": "Regresi贸n Lineal",
        "mlp": "Perceptr贸n Multicapa (MLP)",
        "sequential_nn": "Red Neuronal Secuencial",
        "hybrid_model": "Modelo H铆brido (Red Neuronal + L贸gica Difusa)",
        "train_models": "Entrenar Modelos",
        "generate_report": "Generar Reporte",
        "imputation_complete": "Imputaci贸n completada exitosamente",
        "select_imputation": "Seleccione m茅todo de imputaci贸n",
        "mean_imputation": "Imputaci贸n por Media/Moda",
        "knn_imputation": "Imputaci贸n KNN",
        "iterative_imputation": "Imputaci贸n Iterativa",
        "no_data_loaded": "No se han cargado datos. Por favor, cargue un dataset primero.",
        "data_loaded": "Datos cargados: {} registros, {} variables",
        "preprocessing_first": "Primero debe realizar el preprocesamiento de datos",
        "select_target": "Seleccione la variable objetivo",
        "no_numerical_vars": "No hay variables num茅ricas para an谩lisis",
        "no_models_trained": "No hay modelos entrenados. Por favor, entrene algunos modelos primero."
    },
    "EN": {
        "title": "Housing Price Estimator",
        "welcome": "Welcome to the housing price estimator",
        "upload_data": "Upload data",
        "file_types": "Supported file types: CSV, XLSX",
        "select_file": "Select a file",
        "eda": "Exploratory Data Analysis (EDA)",
        "correlations": "Correlation Analysis",
        "preprocessing": "Cleaning and Preprocessing",
        "scaling": "Scaling and Splitting",
        "modeling": "Modeling",
        "validation": "Training and Validation",
        "timeseries": "Time Series Forecasting",
        "report": "Generate PDF Report",
        "records": "records",
        "variables": "variables",
        "numerical": "Numerical",
        "categorical": "Categorical",
        "missing_data": "Missing data",
        "duplicates": "Duplicate data",
        "descriptive_stats": "Descriptive Statistics",
        "normality_test": "Normality Test",
        "visualization": "Visualization",
        "correlation_matrix": "Correlation Matrix",
        "correlation_heatmap": "Correlation Heatmap",
        "strongest_correlations": "Strongest Correlations with Price",
        "multicolinearity": "Multicollinearity Analysis",
        "vif": "Variance Inflation Factor (VIF)",
        "preprocessing_options": "Preprocessing Options",
        "imputation": "Missing Value Imputation",
        "outlier_treatment": "Outlier Treatment",
        "encoding": "Categorical Variable Encoding",
        "scaling_options": "Scaling Options",
        "train_val_test_split": "Train/Validation/Test Split",
        "cross_validation": "Cross Validation",
        "model_training": "Model Training",
        "model_performance": "Model Performance",
        "timeseries_forecasting": "Time Series Forecasting",
        "download_report": "Download PDF Report",
        "linear_regression": "Linear Regression",
        "mlp": "Multilayer Perceptron (MLP)",
        "sequential_nn": "Sequential Neural Network",
        "hybrid_model": "Hybrid Model (Neural Network + Fuzzy Logic)",
        "train_models": "Train Models",
        "generate_report": "Generate Report",
        "imputation_complete": "Imputation completed successfully",
        "select_imputation": "Select imputation method",
        "mean_imputation": "Mean/Mode Imputation",
        "knn_imputation": "KNN Imputation",
        "iterative_imputation": "Iterative Imputation",
        "no_data_loaded": "No data loaded. Please upload a dataset first.",
        "data_loaded": "Data loaded: {} records, {} variables",
        "preprocessing_first": "You must first preprocess the data",
        "select_target": "Select target variable",
        "no_numerical_vars": "No numerical variables for analysis",
        "no_models_trained": "No models trained. Please train some models first."
    },
    "FR": {
        "title": "Estimateur de Prix Immobiliers",
        "welcome": "Bienvenue dans l'estimateur de prix immobiliers",
        "upload_data": "T茅l茅charger des donn茅es",
        "file_types": "Types de fichiers pris en charge: CSV, XLSX",
        "select_file": "S茅lectionner un fichier",
        "eda": "Analyse Exploratoire (EDA)",
        "correlations": "Analyse des Corr茅lations",
        "preprocessing": "Nettoyage et Pr茅traitement",
        "scaling": "Mise  l'茅chelle et Division",
        "modeling": "Mod茅lisation",
        "validation": "Entra卯nement et Validation",
        "timeseries": "Pr茅visions de S茅ries Chronologiques",
        "report": "G茅n茅rer un Rapport PDF",
        "records": "enregistrements",
        "variables": "variables",
        "numerical": "Num茅riques",
        "categorical": "Cat茅gorielles",
        "missing_data": "Donn茅es manquantes",
        "duplicates": "Donn茅es dupliqu茅es",
        "descriptive_stats": "Statistiques Descriptives",
        "normality_test": "Test de Normalit茅",
        "visualization": "Visualisation",
        "correlation_matrix": "Matrice de Corr茅lation",
        "correlation_heatmap": "Carte de Chaleur des Corr茅lations",
        "strongest_correlations": "Corr茅lations les Plus Fortes avec le Prix",
        "multicolinearity": "Analyse de Multicolin茅arit茅",
        "vif": "Facteur d'Inflation de la Variance (VIF)",
        "preprocessing_options": "Options de Pr茅traitement",
        "imputation": "Imputation des Valeurs Manquantes",
        "outlier_treatment": "Traitement des Valeurs Ab茅rrantes",
        "encoding": "Encodage des Variables Cat茅gorielles",
        "scaling_options": "Options de Mise  l'茅chelle",
        "train_val_test_split": "Division Entra卯nement/Validation/Test",
        "cross_validation": "Validation Crois茅e",
        "model_training": "Entra卯nement des Mod猫les",
        "model_performance": "Performance des Mod猫les",
        "timeseries_forecasting": "Pr茅vision de S茅ries Chronologiques",
        "download_report": "T茅l茅charger le Rapport PDF",
        "linear_regression": "R茅gression Lin茅aire",
        "mlp": "Perceptron Multicouche (MLP)",
        "sequential_nn": "R茅seau Neuronal S茅quentiel",
        "hybrid_model": "Mod猫le Hybride (R茅seau Neuronal + Logique Floue)",
        "train_models": "Entra卯ner les Mod猫les",
        "generate_report": "G茅n茅rer Rapport",
        "imputation_complete": "Imputation termin茅e avec succ猫s",
        "select_imputation": "S茅lectionnez la m茅thode d'imputation",
        "mean_imputation": "Imputation par Moyenne/Mode",
        "knn_imputation": "Imputation KNN",
        "iterative_imputation": "Imputation It茅rative",
        "no_data_loaded": "Aucune donn茅e charg茅e. Veuillez t茅l茅charger un jeu de donn茅es d'abord.",
        "data_loaded": "Donn茅es charg茅es: {} enregistrements, {} variables",
        "preprocessing_first": "Vous devez d'abord pr茅traiter les donn茅es",
        "select_target": "S茅lectionnez la variable cible",
        "no_numerical_vars": "Aucune variable num茅rique pour l'analyse",
        "no_models_trained": "Aucun mod猫le entra卯n茅. Veuillez d'abord entra卯ner des mod猫les."
    }
}

# Inicializaci贸n del estado de la sesi贸n
def initialize_session_state():
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'language' not in st.session_state:
        st.session_state.language = "ES"
    if 'processed_data' not in st.session_state:
        st.session_state.processed_data = None
    if 'target_column' not in st.session_state:
        st.session_state.target_column = None
    if 'models' not in st.session_state:
        st.session_state.models = {}
    if 'X_train' not in st.session_state:
        st.session_state.X_train = None
    if 'X_val' not in st.session_state:
        st.session_state.X_val = None
    if 'X_test' not in st.session_state:
        st.session_state.X_test = None
    if 'y_train' not in st.session_state:
        st.session_state.y_train = None
    if 'y_val' not in st.session_state:
        st.session_state.y_val = None
    if 'y_test' not in st.session_state:
        st.session_state.y_test = None
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "upload"
    if 'imputation_method' not in st.session_state:
        st.session_state.imputation_method = None

# Funci贸n para obtener texto seg煤n el idioma
def get_text(key):
    try:
        return language_dict[st.session_state.language][key]
    except KeyError:
        return f"[{key}]"

# CSS personalizado para el dise帽o
def local_css():
    st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stButton>button {
        background-color: #1f77b4;
        color: white;
        border-radius: 5px;
        border: none;
        padding: 0.5rem 1rem;
        width: 100%;
        margin-bottom: 0.5rem;
    }
    .stButton>button:hover {
        background-color: #0f5d94;
        color: white;
    }
    .sidebar .sidebar-content {
        background-color: #e6f2ff;
    }
    .metric-card {
        background-color: #e6f2ff;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1rem;
    }
    .success-box {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin-bottom: 1rem;
        border: 1px solid #c3e6cb;
    }
    </style>
    """, unsafe_allow_html=True)

# Funci贸n para cargar datos
def load_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
            df = pd.read_excel(uploaded_file)
        else:
            st.error("Formato de archivo no compatible")
            return None
        
        st.success(get_text("data_loaded").format(df.shape[0], df.shape[1]))
        return df
    except Exception as e:
        st.error(f"Error al cargar el archivo: {str(e)}")
        return None

# Funci贸n para realizar EDA
def perform_eda():
    if st.session_state.data is None:
        st.warning(get_text("no_data_loaded"))
        return
    
    df = st.session_state.data
    st.subheader(get_text("eda"))
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(get_text("records"), df.shape[0])
    with col2:
        st.metric(get_text("variables"), df.shape[1])
    with col3:
        numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
        st.metric(get_text("numerical"), len(numerical_cols))
        st.metric(get_text("categorical"), len(categorical_cols))
    
    # Detecci贸n de datos nulos y duplicados
    st.subheader(get_text("missing_data"))
    missing_data = pd.DataFrame({
        'Columna': df.columns,
        'Valores nulos': df.isnull().sum().values,
        'Porcentaje nulos': (df.isnull().sum().values / df.shape[0]) * 100
    })
    st.dataframe(missing_data)
    
    st.subheader(get_text("duplicates"))
    st.write(f"N煤mero de registros duplicados: {df.duplicated().sum()}")
    
    # Estad铆sticas descriptivas
    st.subheader(get_text("descriptive_stats"))
    if len(numerical_cols) > 0:
        st.dataframe(df[numerical_cols].describe())
    else:
        st.warning(get_text("no_numerical_vars"))
    
    # Prueba de normalidad
    st.subheader(get_text("normality_test"))
    if len(numerical_cols) > 0:
        normality_results = []
        for col in numerical_cols:
            col_data = df[col].dropna()
            if len(col_data) > 0:
                try:
                    stat, p_value = kstest(col_data, 'norm')
                    normality_results.append({
                        'Variable': col,
                        'Estad铆stico': stat,
                        'p-valor': p_value,
                        'Normal': p_value > 0.05
                    })
                except:
                    continue
        if normality_results:
            normality_df = pd.DataFrame(normality_results)
            st.dataframe(normality_df)
        else:
            st.warning("No se pudieron realizar pruebas de normalidad")
    
    # Visualizaci贸n
    st.subheader(get_text("visualization"))
    if numerical_cols:
        plot_type = st.selectbox("Tipo de gr谩fico", ["Histograma", "Boxplot", "Scatterplot"])
        
        if plot_type == "Histograma":
            col_to_plot = st.selectbox("Seleccione columna", numerical_cols)
            fig = px.histogram(df, x=col_to_plot, title=f"Histograma de {col_to_plot}")
            st.plotly_chart(fig)
        
        elif plot_type == "Boxplot":
            col_to_plot = st.selectbox("Seleccione columna", numerical_cols)
            fig = px.box(df, y=col_to_plot, title=f"Boxplot de {col_to_plot}")
            st.plotly_chart(fig)
        
        elif plot_type == "Scatterplot" and len(numerical_cols) >= 2:
            col_x = st.selectbox("Seleccione variable X", numerical_cols)
            col_y = st.selectbox("Seleccione variable Y", numerical_cols)
            fig = px.scatter(df, x=col_x, y=col_y, title=f"Scatterplot: {col_x} vs {col_y}")
            st.plotly_chart(fig)

# Funci贸n para an谩lisis de correlaciones
def perform_correlation_analysis():
    if st.session_state.data is None:
        st.warning(get_text("no_data_loaded"))
        return
    
    df = st.session_state.data
    st.subheader(get_text("correlations"))
    
    numerical_df = df.select_dtypes(include=[np.number])
    if numerical_df.empty:
        st.warning(get_text("no_numerical_vars"))
        return
    
    corr_matrix = numerical_df.corr()
    
    st.subheader(get_text("correlation_matrix"))
    st.dataframe(corr_matrix)
    
    st.subheader(get_text("correlation_heatmap"))
    fig = px.imshow(corr_matrix, text_auto=True, aspect="auto", color_continuous_scale='RdBu_r')
    st.plotly_chart(fig)
    
    st.subheader(get_text("strongest_correlations"))
    if st.session_state.target_column and st.session_state.target_column in corr_matrix.columns:
        target_correlations = corr_matrix[st.session_state.target_column].sort_values(key=abs, ascending=False)
        st.dataframe(target_correlations)
        
        top_correlated = target_correlations.index[1:4]
        for col in top_correlated:
            if col in df.columns and st.session_state.target_column in df.columns:
                fig = px.scatter(df, x=col, y=st.session_state.target_column, 
                                title=f"{col} vs {st.session_state.target_column}")
                st.plotly_chart(fig)
    
    st.subheader(get_text("multicolinearity"))
    if len(numerical_df.columns) > 1:
        vif_data = pd.DataFrame()
        vif_data["Variable"] = numerical_df.columns
        
        vif_values = []
        for i in range(len(numerical_df.columns)):
            temp_df = numerical_df.dropna()
            if len(temp_df) > 0:
                try:
                    vif = variance_inflation_factor(temp_df.values, i)
                    vif_values.append(vif)
                except:
                    vif_values.append(np.nan)
            else:
                vif_values.append(np.nan)
        
        vif_data["VIF"] = vif_values
        st.dataframe(vif_data)

# Funci贸n para preprocesamiento de datos
def perform_preprocessing():
    if st.session_state.data is None:
        st.warning(get_text("no_data_loaded"))
        return
    
    df = st.session_state.data
    st.subheader(get_text("preprocessing"))
    
    processed_df = df.copy()
    
    # Selecci贸n de columna objetivo
    numerical_cols = processed_df.select_dtypes(include=[np.number]).columns.tolist()
    if numerical_cols:
        target_col = st.selectbox(get_text("select_target"), numerical_cols)
        st.session_state.target_column = target_col
    
    # Imputaci贸n de valores faltantes
    st.subheader(get_text("imputation"))
    st.session_state.imputation_method = st.selectbox(get_text("select_imputation"), 
                                    [get_text("mean_imputation"), 
                                     get_text("knn_imputation"), 
                                     get_text("iterative_imputation")])
    
    if st.button("Aplicar Imputaci贸n"):
        with st.spinner("Aplicando imputaci贸n..."):
            numerical_cols = processed_df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = processed_df.select_dtypes(include=['object']).columns.tolist()
            
            if st.session_state.imputation_method == get_text("mean_imputation"):
                for col in numerical_cols:
                    if processed_df[col].isnull().sum() > 0:
                        try:
                            mean_val = processed_df[col].mean()
                            processed_df[col].fillna(mean_val, inplace=True)
                        except:
                            st.warning(f"No se pudo calcular la media para {col}")
                
                for col in categorical_cols:
                    if processed_df[col].isnull().sum() > 0:
                        try:
                            mode_val = processed_df[col].mode()[0] if not processed_df[col].mode().empty else "Desconocido"
                            processed_df[col].fillna(mode_val, inplace=True)
                        except:
                            st.warning(f"No se pudo calcular la moda para {col}")
            
            elif st.session_state.imputation_method == get_text("knn_imputation"):
                try:
                    numerical_imputer = KNNImputer(n_neighbors=5)
                    processed_df[numerical_cols] = numerical_imputer.fit_transform(processed_df[numerical_cols])
                    
                    for col in categorical_cols:
                        if processed_df[col].isnull().sum() > 0:
                            try:
                                mode_val = processed_df[col].mode()[0] if not processed_df[col].mode().empty else "Desconocido"
                                processed_df[col].fillna(mode_val, inplace=True)
                            except:
                                st.warning(f"No se pudo calcular la moda para {col}")
                except Exception as e:
                    st.error(f"Error en imputaci贸n KNN: {str(e)}")
            
            elif st.session_state.imputation_method == get_text("iterative_imputation"):
                try:
                    numerical_imputer = IterativeImputer(random_state=42)
                    processed_df[numerical_cols] = numerical_imputer.fit_transform(processed_df[numerical_cols])
                    
                    for col in categorical_cols:
                        if processed_df[col].isnull().sum() > 0:
                            try:
                                mode_val = processed_df[col].mode()[0] if not processed_df[col].mode().empty else "Desconocido"
                                processed_df[col].fillna(mode_val, inplace=True)
                            except:
                                st.warning(f"No se pudo calcular la moda para {col}")
                except Exception as e:
                    st.error(f"Error en imputaci贸n iterativa: {str(e)}")
            
            st.session_state.processed_data = processed_df
            st.markdown(f'<div class="success-box">{get_text("imputation_complete")}</div>', unsafe_allow_html=True)
            st.dataframe(processed_df.head())
    
    # Tratamiento de outliers (solo si ya se aplic贸 imputaci贸n)
    if st.session_state.processed_data is not None:
        st.subheader(get_text("outlier_treatment"))
        outlier_treatment = st.selectbox("M茅todo de tratamiento de outliers", 
                                        ["Ninguno", "Eliminaci贸n", "Transformaci贸n"])
        
        if outlier_treatment != "Ninguno" and st.session_state.target_column:
            numerical_cols = processed_df.select_dtypes(include=[np.number]).columns.tolist()
            if st.session_state.target_column in numerical_cols:
                numerical_cols.remove(st.session_state.target_column)
            
            for col in numerical_cols:
                try:
                    Q1 = processed_df[col].quantile(0.25)
                    Q3 = processed_df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    if outlier_treatment == "Eliminaci贸n":
                        processed_df = processed_df[(processed_df[col] >= lower_bound) & (processed_df[col] <= upper_bound)]
                    elif outlier_treatment == "Transformaci贸n":
                        processed_df[col] = np.log1p(processed_df[col])
                except:
                    st.warning(f"No se pudo procesar outliers para {col}")
            
            st.session_state.processed_data = processed_df
            st.success("Tratamiento de outliers completado")
            st.dataframe(processed_df.head())
    
    # Codificaci贸n de variables categ贸ricas
    if st.session_state.processed_data is not None:
        st.subheader(get_text("encoding"))
        encoding_method = st.selectbox("M茅todo de codificaci贸n", 
                                      ["Ninguno", "One-Hot Encoding", "Label Encoding"])
        
        if encoding_method != "Ninguno":
            categorical_cols = processed_df.select_dtypes(include=['object']).columns.tolist()
            
            if encoding_method == "One-Hot Encoding":
                try:
                    processed_df = pd.get_dummies(processed_df, columns=categorical_cols, drop_first=True)
                except Exception as e:
                    st.error(f"Error en One-Hot Encoding: {str(e)}")
            elif encoding_method == "Label Encoding":
                try:
                    le = LabelEncoder()
                    for col in categorical_cols:
                        processed_df[col] = le.fit_transform(processed_df[col].astype(str))
                except Exception as e:
                    st.error(f"Error en Label Encoding: {str(e)}")
            
            st.session_state.processed_data = processed_df
            st.success("Codificaci贸n completada")
            st.dataframe(processed_df.head())
    
    # Escalado de datos
    if st.session_state.processed_data is not None:
        st.subheader(get_text("scaling_options"))
        scaling_method = st.selectbox("M茅todo de escalado", ["Ninguno", "StandardScaler"])
        
        if scaling_method != "Ninguno" and st.session_state.target_column:
            numerical_cols = processed_df.select_dtypes(include=[np.number]).columns.tolist()
            if st.session_state.target_column in numerical_cols:
                numerical_cols.remove(st.session_state.target_column)
            
            if scaling_method == "StandardScaler":
                try:
                    scaler = StandardScaler()
                    processed_df[numerical_cols] = scaler.fit_transform(processed_df[numerical_cols])
                    st.session_state.processed_data = processed_df
                    st.success("Escalado completado")
                    st.dataframe(processed_df.head())
                except Exception as e:
                    st.error(f"Error en escalado: {str(e)}")
    
    # Divisi贸n de datos
    if st.session_state.processed_data is not None and st.session_state.target_column:
        st.subheader(get_text("train_val_test_split"))
        if st.session_state.target_column in processed_df.columns:
            X = processed_df.drop(st.session_state.target_column, axis=1)
            y = processed_df[st.session_state.target_column]
            
            X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
            X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)
            
            st.write(f"Conjunto de entrenamiento: {X_train.shape[0]} muestras")
            st.write(f"Conjunto de validaci贸n: {X_val.shape[0]} muestras")
            st.write(f"Conjunto de prueba: {X_test.shape[0]} muestras")
            
            st.session_state.X_train = X_train
            st.session_state.X_val = X_val
            st.session_state.X_test = X_test
            st.session_state.y_train = y_train
            st.session_state.y_val = y_val
            st.session_state.y_test = y_test
            
            st.subheader(get_text("cross_validation"))
            k_folds = st.slider("N煤mero de folds para validaci贸n cruzada", 3, 10, 5)

# Funci贸n para preparar datos para modelado
def prepare_data_for_modeling(X_data):
    """Prepara los datos eliminando o codificando variables categ贸ricas"""
    X_clean = X_data.copy()
    
    # Identificar columnas no num茅ricas
    non_numeric_cols = X_clean.select_dtypes(exclude=[np.number]).columns.tolist()
    
    if non_numeric_cols:
        st.warning(f"Columnas no num茅ricas encontradas: {non_numeric_cols}. Aplicando codificaci贸n...")
        
        # Para cada columna no num茅rica, intentar codificaci贸n
        for col in non_numeric_cols:
            try:
                # Intentar convertir a num茅rico primero
                X_clean[col] = pd.to_numeric(X_clean[col], errors='coerce')
                
                # Si todav铆a hay NaN, usar Label Encoding
                if X_clean[col].isnull().any():
                    le = LabelEncoder()
                    # Rellenar NaN con un valor temporal para encoding
                    X_clean[col] = X_clean[col].fillna('Missing')
                    X_clean[col] = le.fit_transform(X_clean[col].astype(str))
            except:
                # Si falla la conversi贸n, usar Label Encoding directamente
                try:
                    le = LabelEncoder()
                    X_clean[col] = le.fit_transform(X_clean[col].astype(str))
                except:
                    st.error(f"No se pudo codificar la columna {col}. Se eliminar谩.")
                    X_clean = X_clean.drop(columns=[col])
    
    # Verificar y manejar valores NaN
    if X_clean.isnull().any().any():
        st.warning("Existen valores NaN. Aplicando imputaci贸n...")
        numeric_cols = X_clean.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            imputer = SimpleImputer(strategy='mean')
            X_clean[numeric_cols] = imputer.fit_transform(X_clean[numeric_cols])
    
    return X_clean

# Modelo h铆brido de red neuronal con l贸gica difusa
def create_hybrid_model(input_dim):
    # Parte de red neuronal
    model = Sequential([
        Dense(64, activation='relu', input_shape=(input_dim,)),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    
    model.compile(optimizer=Adam(learning_rate=0.001), 
                 loss='mse', 
                 metrics=['mae'])
    
    return model

# Funci贸n para entrenar modelos
def train_models():
    if (st.session_state.X_train is None or st.session_state.y_train is None or 
        st.session_state.X_val is None or st.session_state.y_val is None):
        st.warning(get_text("preprocessing_first"))
        return
    
    st.subheader(get_text("model_training"))
    
    X_train = st.session_state.X_train
    y_train = st.session_state.y_train
    X_val = st.session_state.X_val
    y_val = st.session_state.y_val
    
    # Preparar datos para modelado
    X_train_clean = prepare_data_for_modeling(X_train)
    X_val_clean = prepare_data_for_modeling(X_val)
    
    models = {}
    
    # 1. Regresi贸n Lineal
    if st.button(get_text("linear_regression")):
        with st.spinner("Entrenando Regresi贸n Lineal..."):
            try:
                start_time = time.time()
                lr_model = LinearRegression()
                lr_model.fit(X_train_clean, y_train)
                training_time = time.time() - start_time
                
                models['Linear Regression'] = {
                    'model': lr_model,
                    'training_time': training_time,
                    'feature_names': X_train_clean.columns.tolist()
                }
                
                st.success(f"Regresi贸n Lineal entrenada en {training_time:.2f} segundos")
                
                # Mostrar coeficientes
                coef_df = pd.DataFrame({
                    'Variable': X_train_clean.columns,
                    'Coeficiente': lr_model.coef_
                }).sort_values('Coeficiente', key=abs, ascending=False)
                
                st.subheader("Coeficientes del Modelo")
                st.dataframe(coef_df.head(10))
                
            except Exception as e:
                st.error(f"Error entrenando Regresi贸n Lineal: {str(e)}")
    
    # 2. Perceptr贸n Multicapa (MLP)
    if st.button(get_text("mlp")):
        with st.spinner("Entrenando MLP..."):
            try:
                start_time = time.time()
                
                mlp_model = Sequential([
                    Dense(64, activation='relu', input_shape=(X_train_clean.shape[1],)),
                    Dropout(0.2),
                    Dense(32, activation='relu'),
                    Dropout(0.2),
                    Dense(1)
                ])
                mlp_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
                history = mlp_model.fit(X_train_clean, y_train, 
                                       epochs=100, batch_size=32, 
                                       validation_data=(X_val_clean, y_val),
                                       verbose=0)
                training_time = time.time() - start_time
                
                models['MLP'] = {
                    'model': mlp_model,
                    'training_time': training_time,
                    'history': history,
                    'feature_names': X_train_clean.columns.tolist()
                }
                
                st.success(f"MLP entrenado en {training_time:.2f} segundos")
                
                # Gr谩fico de p茅rdida durante el entrenamiento
                fig = px.line(x=range(len(history.history['loss'])), 
                             y=history.history['loss'], 
                             labels={'x': 'poca', 'y': 'P茅rdida'}, 
                             title='P茅rdida durante el entrenamiento (MLP)')
                st.plotly_chart(fig)
                
            except Exception as e:
                st.error(f"Error entrenando MLP: {str(e)}")
    
    # 3. Red Neuronal Secuencial
    if st.button(get_text("sequential_nn")):
        with st.spinner("Entrenando Red Neuronal Secuencial..."):
            try:
                start_time = time.time()
                
                sequential_model = Sequential([
                    Dense(128, activation='relu', input_shape=(X_train_clean.shape[1],)),
                    Dropout(0.3),
                    Dense(64, activation='relu'),
                    Dropout(0.3),
                    Dense(32, activation='relu'),
                    Dense(1)
                ])
                sequential_model.compile(optimizer=Adam(learning_rate=0.001), 
                                        loss='mse', 
                                        metrics=['mae'])
                history = sequential_model.fit(X_train_clean, y_train, 
                                              epochs=150, batch_size=32, 
                                              validation_data=(X_val_clean, y_val),
                                              verbose=0)
                training_time = time.time() - start_time
                
                models['Sequential NN'] = {
                    'model': sequential_model,
                    'training_time': training_time,
                    'history': history,
                    'feature_names': X_train_clean.columns.tolist()
                }
                
                st.success(f"Red Neuronal Secuencial entrenada en {training_time:.2f} segundos")
                
                # Gr谩fico de p茅rdida durante el entrenamiento
                fig = px.line(x=range(len(history.history['loss'])), 
                             y=history.history['loss'], 
                             labels={'x': 'poca', 'y': 'P茅rdida'}, 
                             title='P茅rdida durante el entrenamiento (Red Secuencial)')
                st.plotly_chart(fig)
                
            except Exception as e:
                st.error(f"Error entrenando Red Neuronal Secuencial: {str(e)}")
    
    # 4. Modelo H铆brido (Red Neuronal + L贸gica Difusa)
    if st.button(get_text("hybrid_model")):
        with st.spinner("Entrenando Modelo H铆brido..."):
            try:
                start_time = time.time()
                
                # Parte de red neuronal
                hybrid_model = create_hybrid_model(X_train_clean.shape[1])
                history = hybrid_model.fit(X_train_clean, y_train, 
                                          epochs=100, batch_size=32, 
                                          validation_data=(X_val_clean, y_val),
                                          verbose=0)
                training_time = time.time() - start_time
                
                models['Hybrid Model'] = {
                    'model': hybrid_model,
                    'training_time': training_time,
                    'history': history,
                    'feature_names': X_train_clean.columns.tolist()
                }
                
                st.success(f"Modelo H铆brido entrenado en {training_time:.2f} segundos")
                
                # Gr谩fico de p茅rdida durante el entrenamiento
                fig = px.line(x=range(len(history.history['loss'])), 
                             y=history.history['loss'], 
                             labels={'x': 'poca', 'y': 'P茅rdida'}, 
                             title='P茅rdida durante el entrenamiento (Modelo H铆brido)')
                st.plotly_chart(fig)
                
                # Explicaci贸n del modelo h铆brido
                with st.expander("Explicaci贸n del Modelo H铆brido"):
                    st.write("""
                    Este modelo combina una red neuronal profunda con elementos de l贸gica difusa:
                    - La red neuronal aprende patrones complejos en los datos
                    - La l贸gica difusa ayuda a manejar la incertidumbre y proporciona interpretabilidad
                    - El dropout regulariza el modelo para prevenir sobreajuste
                    """)
                
            except Exception as e:
                st.error(f"Error entrenando Modelo H铆brido: {str(e)}")
    
    # Actualizar modelos en el estado de la sesi贸n
    if models:
        st.session_state.models.update(models)

# Funci贸n para validaci贸n y m茅tricas
def perform_validation():
    st.subheader(get_text("model_performance"))
    
    if not st.session_state.models:
        st.warning(get_text("no_models_trained"))
        return
    
    if st.session_state.X_val is None or st.session_state.y_val is None:
        st.warning("No hay datos de validaci贸n disponibles")
        return
    
    # Preparar datos de validaci贸n
    X_val_clean = prepare_data_for_modeling(st.session_state.X_val)
    y_val = st.session_state.y_val
    
    results = []
    for name, model_info in st.session_state.models.items():
        model = model_info['model']
        training_time = model_info['training_time']
        
        if hasattr(model, 'predict'):
            try:
                y_pred = model.predict(X_val_clean)
                
                if len(y_pred.shape) > 1:
                    y_pred = y_pred.flatten()
                
                mae = mean_absolute_error(y_val, y_pred)
                rmse = np.sqrt(mean_squared_error(y_val, y_pred))
                r2 = r2_score(y_val, y_pred)
                
                results.append({
                    'Modelo': name,
                    'MAE': mae,
                    'RMSE': rmse,
                    'R虏': r2,
                    'Tiempo de entrenamiento (s)': training_time
                })
            except Exception as e:
                st.warning(f"No se pudieron calcular m茅tricas para {name}: {str(e)}")
    
    if results:
        results_df = pd.DataFrame(results)
        st.dataframe(results_df.style.format({
            'MAE': '{:.4f}',
            'RMSE': '{:.4f}',
            'R虏': '{:.4f}',
            'Tiempo de entrenamiento (s)': '{:.2f}'
        }))
        
        # Gr谩fico de comparaci贸n de modelos
        fig = go.Figure()
        fig.add_trace(go.Bar(x=results_df['Modelo'], y=results_df['R虏'], name='R虏'))
        fig.update_layout(title='Comparaci贸n de R虏 entre modelos', 
                         xaxis_title='Modelo', yaxis_title='R虏',
                         yaxis_range=[0, 1])
        st.plotly_chart(fig)
        
        # Gr谩fico de comparaci贸n de errores
        fig = go.Figure()
        fig.add_trace(go.Bar(x=results_df['Modelo'], y=results_df['MAE'], name='MAE'))
        fig.add_trace(go.Bar(x=results_df['Modelo'], y=results_df['RMSE'], name='RMSE'))
        fig.update_layout(title='Comparaci贸n de Errores entre modelos', 
                         xaxis_title='Modelo', yaxis_title='Error')
        st.plotly_chart(fig)
    else:
        st.warning("No se pudieron calcular m茅tricas para los modelos")

# Funci贸n para generar reporte
def generate_report():
    st.subheader(get_text("report"))
    st.warning("Esta funcionalidad estar谩 disponible en la pr贸xima versi贸n")
    
    # Aqu铆 se implementar铆a la generaci贸n del reporte PDF
    # con todas las m茅tricas, gr谩ficos y resultados

# Funci贸n principal
def main():
    initialize_session_state()
    local_css()
    
    # Sidebar con botones de navegaci贸n
    with st.sidebar:
        st.markdown("<h1 style='text-align: center; font-size: 80px;'></h1>", unsafe_allow_html=True)
        st.title(get_text("title"))
        
        # Selector de idioma
        st.session_state.language = st.selectbox("Idioma/Language/Langue", options=["ES", "EN", "FR"])
        
        # Carga de datos
        st.header(get_text("upload_data"))
        uploaded_file = st.file_uploader(get_text("select_file"), type=['csv', 'xlsx', 'xls'])
        
        if uploaded_file is not None and st.session_state.data is None:
            st.session_state.data = load_data(uploaded_file)
        
        # Navegaci贸n con botones
        st.header("Navegaci贸n")
        
        if st.button(get_text("eda")):
            st.session_state.current_page = "eda"
        
        if st.button(get_text("correlations")):
            st.session_state.current_page = "correlations"
        
        if st.button(get_text("preprocessing")):
            st.session_state.current_page = "preprocessing"
        
        if st.button(get_text("train_models")):
            st.session_state.current_page = "modeling"
        
        if st.button(get_text("validation")):
            st.session_state.current_page = "validation"
        
        if st.button(get_text("generate_report")):
            st.session_state.current_page = "report"
    
    # P谩gina principal
    st.markdown(f'<h1 class="main-header">{get_text("title")}</h1>', unsafe_allow_html=True)
    
    # Mostrar la p谩gina actual seg煤n la selecci贸n
    if st.session_state.current_page == "eda":
        perform_eda()
    
    elif st.session_state.current_page == "correlations":
        perform_correlation_analysis()
    
    elif st.session_state.current_page == "preprocessing":
        perform_preprocessing()
    
    elif st.session_state.current_page == "modeling":
        train_models()
    
    elif st.session_state.current_page == "validation":
        perform_validation()
    
    elif st.session_state.current_page == "report":
        generate_report()
    
    # Mostrar estado actual de la aplicaci贸n
    with st.expander("Estado de la Aplicaci贸n"):
        st.write(f"**Datos cargados:** {st.session_state.data is not None}")
        if st.session_state.data is not None:
            st.write(f"**Forma de los datos:** {st.session_state.data.shape}")
        st.write(f"**Datos preprocesados:** {st.session_state.processed_data is not None}")
        st.write(f"**Variable objetivo:** {st.session_state.target_column}")
        st.write(f"**Modelos entrenados:** {len(st.session_state.models)}")
        st.write(f"**P谩gina actual:** {st.session_state.current_page}")

if __name__ == "__main__":
    main()
